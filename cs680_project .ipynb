{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs680_project.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "PLR3ra6tmmSV"
      },
      "source": [
        "import numpy as np\r\n",
        "from google.colab import files\r\n",
        "uploaded = files.upload()\r\n",
        "train_dataset=np.load('mytraindata.npy')\r\n",
        "test_dataset=np.load('mytestdata.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XBgCQ0T-qOCI"
      },
      "source": [
        "from sklearn.ensemble import GradientBoostingRegressor\r\n",
        "from sklearn.datasets import make_regression\r\n",
        "from sklearn.ensemble import RandomForestRegressor\r\n",
        "from sklearn.datasets import make_regression\r\n",
        "from sklearn.metrics import mean_squared_error\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "from sklearn import svm\r\n",
        "from sklearn.svm import SVR\r\n",
        "import numpy as np # linear algebra\r\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\r\n",
        "import csv\r\n",
        "from io import StringIO\r\n",
        "from sklearn import preprocessing\r\n",
        "import shutil\r\n",
        "import os\r\n",
        "from numpy import argmax \r\n",
        "import torch\r\n",
        "import torch.utils.data\r\n",
        "from torch import nn, optim\r\n",
        "from torch.nn import functional as F\r\n",
        "from torchvision import datasets, transforms\r\n",
        "from torchvision.utils import save_image\r\n",
        "from IPython.display import Image, display\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import os \r\n",
        "import cv2\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import torch\r\n",
        "from torch.autograd import Variable\r\n",
        "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\r\n",
        "from torch.optim import Adam, SGD\r\n",
        "from sklearn.gaussian_process import GaussianProcessRegressor\r\n",
        "from sklearn.gaussian_process.kernels import DotProduct, WhiteKernel,RBF, ConstantKernel\r\n",
        "from sklearn.ensemble import GradientBoostingRegressor\r\n",
        "from sklearn.datasets import make_regression\r\n",
        "from sklearn import linear_model\r\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FDGDgZ3XOn6v"
      },
      "source": [
        "Gradient boost technique\r\n",
        "after running the next  cell, best parameters for Gradient boosting is printed ,we use those parameters in the next cell to make prediction, then we can run the last two cells for getting the required format for kaggle website."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4tbIBT4muI5"
      },
      "source": [
        "\r\n",
        "\r\n",
        "# Gradient Boosting\r\n",
        "gradboost = GradientBoostingRegressor(random_state = 1)\r\n",
        "learning_rates = [0.1, 0.5, 0.75,1]\r\n",
        "n_estimators = [1, 2, 4, 8, 16, 32, 64, 100]\r\n",
        "max_depth = [1, 4, 8, 10, 20]\r\n",
        "min_samples_split=[1,3,5,8,10]\r\n",
        "min_samples_leaf=[1,3,7,10]\r\n",
        "max_features=[1,3,6,10]\r\n",
        "hyperF = dict(n_estimators = n_estimators, max_depth = max_depth, min_samples_split=min_samples_split,min_samples_leaf = min_samples_leaf,max_features=max_features,learning_rate=learning_rates)\r\n",
        "gridF = GridSearchCV(gradboost, hyperF, cv = 7, verbose = 1, n_jobs = -1)\r\n",
        "bestF = gridF.fit(train_dataset[:,1:80], train_dataset[:,80])\r\n",
        "best_parameter=bestF.best_estimator_\r\n",
        "print(best_parameter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwK9MG_jovVV"
      },
      "source": [
        "mygradboost=GradientBoostingRegressor( min_samples_leaf=3,min_samples_split=3,n_estimators=100,max_depth=10,max_features=6,learning_rate=0.1)\r\n",
        "mygradboost.fit(train_dataset[:,1:80],train_dataset[:,80])\r\n",
        "prediction=mygradboost.predict(test_dataset[:,1:80])"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X_5pn0pRPKOb"
      },
      "source": [
        "Random Forest technique\r\n",
        "after running the next  cell, best parameters for Random Forest are printed ,we use those parameters in the next cell to make prediction, then we can run the last two cells for getting the required format for kaggle website."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "193UkEjsqRaO",
        "outputId": "3bd0b977-d702-47e3-816a-89ea61e63cd2"
      },
      "source": [
        "#Random Forest\r\n",
        "forest = RandomForestRegressor(random_state = 1)\r\n",
        "n_estimators = [10,50,90,130,170]\r\n",
        "max_depth = [1,4,8,10,15]\r\n",
        "min_samples_split = [1,2,3,4,5]\r\n",
        "min_samples_leaf = [ 1,2, 5, 7,10] \r\n",
        "hyperF = dict(n_estimators = n_estimators, max_depth = max_depth,  min_samples_split = min_samples_split, min_samples_leaf = min_samples_leaf)\r\n",
        "gridF = GridSearchCV(forest, hyperF, cv = 7, verbose = 1, n_jobs = -1)\r\n",
        "bestF = gridF.fit(train_dataset[:,1:80], train_dataset[:,80])\r\n",
        "best_parameter=bestF.best_estimator_\r\n",
        "print(best_parameter)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 7 folds for each of 625 candidates, totalling 4375 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  74 tasks      | elapsed:    8.6s\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2APtw9durNNU"
      },
      "source": [
        "myrandomforrest=RandomForestRegressor( min_samples_leaf=1,min_samples_split=4,n_estimators=50,max_depth=10)\r\n",
        "myrandomforrest.fit(train_dataset[:,1:80],train_dataset[:,80])\r\n",
        "prediction=myrandomforrest.predict(test_dataset[:,1:80])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIXuSCI-Pkqd"
      },
      "source": [
        "SVM technique after running the next cell, best parameters for SVM are printed ,we use those parameters in the next cell to make prediction, then we can run the last two cells for getting the required format for kaggle website."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I92vezzcsQBg",
        "outputId": "4083475b-c571-4e3d-ab62-5e748672306c"
      },
      "source": [
        "#SVM\r\n",
        "c=[1,2,3,4,5,6,7,8,9,10]\r\n",
        "ker=['linear', 'rbf','poly']\r\n",
        "parameters = dict(C=c,kernel=ker)\r\n",
        "svc = svm.SVC()\r\n",
        "clf = GridSearchCV(svc, parameters)\r\n",
        "bestF=clf.fit(train_dataset[:,1:80],train_dataset[:,80])\r\n",
        "best_parameters=bestF.best_estimator_\r\n",
        "print(best_parameters)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_split.py:667: UserWarning: The least populated class in y has only 1 members, which is less than n_splits=5.\n",
            "  % (min_groups, self.n_splits)), UserWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "SVC(C=1, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
            "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
            "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
            "    tol=0.001, verbose=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmfVVScysf1U"
      },
      "source": [
        "mysvm=SVR()\r\n",
        "mysvm.fit(train_dataset[:,1:80],train_dataset[:,80])\r\n",
        "prediction=mysvm.predict(test_dataset[:,1:80])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5KKiIvrP_b8"
      },
      "source": [
        "next 3 cells are for neural network. to change the architecture,change dimensions of layers in next cell"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CPZTiTCSttMk"
      },
      "source": [
        "#Neural network\r\n",
        "class network(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(network, self).__init__()\r\n",
        "\r\n",
        "        self.lin = nn.Linear(79, 65536)\r\n",
        "        self.drop=nn.Dropout(p=0.2)\r\n",
        "        self.lin3=nn.Linear(65536,1)\r\n",
        "        \r\n",
        "        \r\n",
        "    def forward(self, x):\r\n",
        "        x=F.relu(self.lin(x))\r\n",
        "        x=self.drop(x)\r\n",
        "        x=(self.lin3(x))      \r\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "efdKo9HXuTgO"
      },
      "source": [
        "criterion = torch.nn.MSELoss\r\n",
        "\r\n",
        "# run on GPU if possible\r\n",
        "cuda = torch.cuda.is_available()\r\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\r\n",
        "batch_size = 256\r\n",
        "model=network().to(device)\r\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-3)\r\n",
        "\r\n",
        "max_epochs=500\r\n",
        "totalloss=0\r\n",
        "minloss=float('inf')\r\n",
        "\r\n",
        "\r\n",
        "my_loader = torch.utils.data.DataLoader(train_dataset[0:1400,1:80],batch_size)\r\n",
        "mytargetloader=torch.utils.data.DataLoader(train_dataset[0:1400,80],batch_size)\r\n",
        "\r\n",
        "my_loader_test = torch.utils.data.DataLoader(train_dataset[1400:,1:80],batch_size)\r\n",
        "mytargetloader_test=torch.utils.data.DataLoader(train_dataset[1400:,80],batch_size)\r\n",
        "  \r\n",
        "for i in range(max_epochs):\r\n",
        "  if(totalloss<minloss and i>0):\r\n",
        "    torch.save(model, 'best_model.pt')\r\n",
        "    minloss=totalloss\r\n",
        "  \r\n",
        "  totalloss=0\r\n",
        "\r\n",
        "  for idx,(data,target) in enumerate(zip(my_loader,mytargetloader)):\r\n",
        "    data = data.to(device).float()   \r\n",
        "    target=target.to(device).float()\r\n",
        "    optimizer.zero_grad()\r\n",
        "    predicted_batch = model(data)\r\n",
        "\r\n",
        "    loss = criterion()(predicted_batch, target.reshape((-1,1)))\r\n",
        "    loss.backward() \r\n",
        "    optimizer.step()\r\n",
        "  \r\n",
        "  for idx,(datat,targett) in enumerate(zip(my_loader_test,mytargetloader_test)):\r\n",
        "    datat = datat.to(device).float()   \r\n",
        "    targett=targett.to(device).float()\r\n",
        "    predicted_batcht = model(datat)\r\n",
        "    loss2 = criterion()(predicted_batcht, targett.reshape((-1,1)))\r\n",
        "    totalloss+=loss2.item()\r\n",
        "  \r\n",
        "  print(str(i)+\" \"+str(totalloss))\r\n",
        "print(minloss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IlSjEW_3uay2"
      },
      "source": [
        "criterion3 = torch.nn.MSELoss\r\n",
        "# run on GPU if possible\r\n",
        "cuda = torch.cuda.is_available()\r\n",
        "device = torch.device(\"cuda\" if cuda else \"cpu\")\r\n",
        "batch_size = 128\r\n",
        "myfinalmodel = torch.load('best_model.pt')\r\n",
        "myfinalmodel.eval()\r\n",
        "myfinalloader1=torch.utils.data.DataLoader(test_dataset[:,1:80], batch_size)\r\n",
        "final_prediction=np.zeros((len(test_dataset),1))\r\n",
        "j=0\r\n",
        "\r\n",
        "with torch.no_grad(): \r\n",
        "  for idx,(data1f) in enumerate((myfinalloader1)):\r\n",
        "    data1f = data1f.to(device).float()   \r\n",
        "    predicted_batchf = myfinalmodel(data1f)\r\n",
        "    for k in range(len(predicted_batchf)):\r\n",
        "      final_prediction[j][0]=predicted_batchf[k]\r\n",
        "      j+=1\r\n",
        "\r\n",
        "print(final_prediction.shape)\r\n",
        "prediction=final_prediction"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvBLp-EWQJZj"
      },
      "source": [
        "Gaussian processs, taken from my own submission for assignment 3 where we used identity and polynomial kernels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXlT6CFAuhXU"
      },
      "source": [
        "#Gaussian Process\r\n",
        "def predict_gaussian_process(inputs, posterior):\r\n",
        "\r\n",
        "  mean = np.zeros(inputs.shape[0])\r\n",
        "  variance = np.zeros(inputs.shape[0])\r\n",
        "  mean,variance=posterior(inputs) \r\n",
        "  return mean, variance\r\n",
        "\r\n",
        "def eval_gaussian_process(inputs, posterior, targets):\r\n",
        "  mean_squared_error = 0\r\n",
        "  predicted_mean_values,predicted_variance=predict_gaussian_process(inputs, posterior)\r\n",
        "  diff=predicted_mean_values-targets\r\n",
        "  mean_squared_error =(diff**2).mean(axis=0)\r\n",
        "  return mean_squared_error\r\n",
        "\r\n",
        "\r\n",
        "def train_gaussian_process(train_inputs, train_targets, measurement_variance, kernel, kernel_param):\r\n",
        "  inverse_regularized_gram_matrix = np.zeros((train_inputs.shape[0],train_inputs.shape[0]))\r\n",
        "  K=kernel(train_inputs,train_inputs,kernel_param)\r\n",
        "  I=np.eye(train_inputs.shape[0])\r\n",
        "  inverse_regularized_gram_matrix=np.linalg.inv(K+measurement_variance*I)\r\n",
        "\r\n",
        "  def posterior(inputs, train_inputs=train_inputs, train_targets=train_targets, inverse_regularized_gram_matrix=inverse_regularized_gram_matrix, kernel=kernel):\r\n",
        "\r\n",
        "    mean = np.zeros(inputs.shape[0])\r\n",
        "    mean=(kernel(inputs,train_inputs,kernel_param).dot(inverse_regularized_gram_matrix)).dot(train_targets)\r\n",
        "    variance = np.zeros(inputs.shape[0])\r\n",
        "    variance=kernel(inputs,inputs,kernel_param)+measurement_variance*np.eye(len(inputs))-(kernel(inputs,train_inputs,kernel_param).dot(inverse_regularized_gram_matrix)).dot(kernel(train_inputs,inputs,kernel_param))\r\n",
        "    return mean, variance\r\n",
        "\r\n",
        "  return posterior\r\n",
        "\r\n",
        "def identity_kernel(inputs1,inputs2,dummy_param=None):\r\n",
        "  gram_matrix = np.zeros((inputs1.shape[0],inputs2.shape[0]))\r\n",
        "  gram_matrix=inputs1.dot(inputs2.transpose())\r\n",
        "  return gram_matrix\r\n",
        "\r\n",
        "def polynomial_kernel(inputs1,inputs2,degree):\r\n",
        "  gram_matrix = np.zeros((inputs1.shape[0],inputs2.shape[0]))\r\n",
        "  gram_matrix=((inputs1.dot(inputs2.transpose())+1)**degree)\r\n",
        "  return gram_matrix\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "def cross_validation_gaussian_process(k_folds, kernel, hyperparameters, inputs, targets, measurement_variance):\r\n",
        "\r\n",
        "  best_hyperparam = 0\r\n",
        "  best_mean_squared_error = 0\r\n",
        "  mean_squared_errors = np.zeros(len(hyperparameters))\r\n",
        "\r\n",
        "  j=0\r\n",
        "  data_length = len(inputs)\r\n",
        "  interval_length = data_length // k_folds\r\n",
        "  for a in hyperparameters:\r\n",
        "    sum_MSE = 0\r\n",
        "    for i in range(k_folds):\r\n",
        "      start_index = i * interval_length\r\n",
        "      train_inputs = np.concatenate((inputs[0:start_index], inputs[start_index + interval_length:]))\r\n",
        "      train_targets = np.concatenate((targets[0:start_index], targets[start_index + interval_length:]))\r\n",
        "      myposterior=train_gaussian_process(train_inputs, train_targets, measurement_variance, kernel, a)\r\n",
        "      sum_MSE+=eval_gaussian_process(inputs[start_index:start_index+interval_length], myposterior, targets[start_index:start_index+interval_length])\r\n",
        "      \r\n",
        "    mean_squared_errors[j] = (sum_MSE/k_folds)\r\n",
        "    j+=1\r\n",
        "\r\n",
        "  best_mean_squared_error = float(\"inf\")\r\n",
        "  for k in range(len(hyperparameters)):\r\n",
        "    if(best_mean_squared_error>mean_squared_errors[k]):\r\n",
        "      best_mean_squared_error=mean_squared_errors[k]\r\n",
        "      best_hyperparam=hyperparameters[k]\r\n",
        "  return best_hyperparam, best_mean_squared_error, mean_squared_errors"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wzCgHH6yy0J"
      },
      "source": [
        "train_inputs=train_dataset[:,1:80]\r\n",
        "train_targets=train_dataset[:,80]\r\n",
        "test_inputs=test_dataset[:,1:80]\r\n",
        "measurement_variance = 1\r\n",
        "k_folds = 10\r\n",
        "\r\n",
        "# identity kernel\r\n",
        "posterior = train_gaussian_process(train_inputs, train_targets, measurement_variance, identity_kernel, None)\r\n",
        "mean,var=predict_gaussian_process(test_inputs, posterior)\r\n",
        "\r\n",
        "# polynomial kernel\r\n",
        "\r\n",
        "hyperparams = range(1,21)\r\n",
        "best_degree, best_mean_squared_error, mean_squared_errors = cross_validation_gaussian_process(k_folds,polynomial_kernel,hyperparams,train_inputs,train_targets,measurement_variance)\r\n",
        "print('best degree: ' + str (best_degree))\r\n",
        "posterior = train_gaussian_process(train_inputs, train_targets, measurement_variance, polynomial_kernel, best_degree)\r\n",
        "mean,var=predict_gaussian_process(test_inputs, posterior)\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGTlJSe4LhnL"
      },
      "source": [
        "prediction=mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xL14xIn0J8nO"
      },
      "source": [
        "kernel=ConstantKernel()+DotProduct()\r\n",
        "gpr = GaussianProcessRegressor(kernel=kernel, alpha=5,random_state=0).fit(train_dataset[:,1:80], train_dataset[:,80])\r\n",
        "prediction=gpr.predict(test_dataset[:,1:80])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AxXQTuxeQY8O"
      },
      "source": [
        "linear  regression tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 324
        },
        "id": "EZdNoc7g5S9V",
        "outputId": "a8f109df-efcd-45d9-abde-587b4401d3a8"
      },
      "source": [
        "#linear regression\r\n",
        "\r\n",
        "list_mse=[]\r\n",
        "bestb=1\r\n",
        "bestmse=float('inf')\r\n",
        "for b in range(1,200):\r\n",
        " reg = linear_model.Ridge(alpha=b)\r\n",
        " reg.fit(train_dataset[0:1000,1:80],train_dataset[0:1000,80])\r\n",
        " predict=reg.predict(train_dataset[1000:,1:80])\r\n",
        " mse=mean_squared_error(train_dataset[1000:,80],predict)\r\n",
        " list_mse.append(mse)\r\n",
        " if(mse<bestmse):\r\n",
        "   bestmse=mse\r\n",
        "   bestb=b\r\n",
        "print(bestb)\r\n",
        "def plot_linear_regression_mean_squared_errors(mean_squared_errors,hyperparams):\r\n",
        "  plt.plot(hyperparams,mean_squared_errors)\r\n",
        "  plt.ylabel('mean squared error')\r\n",
        "  plt.xlabel('lambda')\r\n",
        "  plt.show()\r\n",
        "hyperparams=range(1,200)\r\n",
        "print(hyperparams)\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "plot_linear_regression_mean_squared_errors(list_mse,hyperparams)\r\n",
        "\r\n",
        "reg = linear_model.Ridge(alpha=bestb)\r\n",
        "reg.fit(train_dataset[:,1:80],train_dataset[:,80])\r\n",
        "weights=reg.coef_\r\n",
        "prediction=reg.predict(test_dataset[:,1:80])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "111\n",
            "range(1, 200)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAERCAYAAABhKjCtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deZzddX3v8df7nNkzM5lJZrKQlX1tWAwUARfUKm7gXnGhl+Kl3qtUa72tS6ve9i5qXS4ulaJS1FLaqwXF3lapoICKQEgCJCSQGEgg20zWmSSzz+f+8ftNchJmwgnJOb8zM+/n43E4v/P7/eacD7+Z/D7nuysiMDMzO1Qu6wDMzKwyOUGYmdmonCDMzGxUThBmZjYqJwgzMxuVE4SZmY1qwiUISTdJ6pC0oohzF0i6S9Kjkn4haW45YjQzGw8mXIIAbgYuK/LcLwDfjYhFwF8B/7tUQZmZjTcTLkFExL3AjsJ9kk6U9BNJD0u6T9Jp6aEzgLvT7Z8DV5QxVDOzijbhEsQYbgSui4gXAR8F/jbd/wjwlnT7zUCTpOkZxGdmVnGqsg6g1CQ1AhcB35c0srs2ff4o8DVJ/wm4F9gIDJU7RjOzSjThEwRJKWlXRJxz6IGI2ERagkgTyVsjYleZ4zMzq0gTvoopIrqApyS9HUCJs9PtNkkj1+DjwE0ZhWlmVnEmXIKQdCtwP3CqpGclXQO8G7hG0iPASg40Rr8ceELSk8BM4H9mELKZWUWSp/s2M7PRTLgShJmZHRsTqpG6ra0tFi5cmHUYZmbjxsMPP7wtItpHOzahEsTChQtZsmRJ1mGYmY0bktaPdcxVTGZmNqqSJYjnmzRPUquk29OJ8h6UdFbBsT+RtFLSCkm3SqorVZxmZja6UpYgbubwk+Z9AlieTpR3FXA9gKQ5wB8DiyPiLCAPvLOEcZqZ2ShKliBGmzTvEPsnyouI1cBCSTPTY1VAvaQqoAHYVKo4zcxsdFm2QeyfKE/SBcACYG5EbCSZhnsDsBnYHRF3ZhalmdkklWWC+CzQImk5cB2wDBiS1Eoy0vl44DhgiqT3jPUmkq6VtETSks7OznLEbWY2KWSWICKiKyKuTifRuwpoB9YBrwKeiojOiBgAbiOZjXWs97kxIhZHxOL29lG78pqZ2QuQWYKQ1CKpJn35PuDedGK9DcCFkhqUzM/9SmBVKWP5yl1ruOdJlz7MzAqVspvrcybNk/R+Se9PTzkdWCHpCeC1wIcAIuIB4AfAUuCxNMYbSxUnwA33/Jb7nCDMzA5SspHUEXHl8xy/HzhljGOfBj5dirhGU1uVo39ouFwfZ2Y2LngkNVBbladvwAnCzKyQEwRQU5Wjb9ArjZqZFXKCIKli6ht0CcLMrJATBFBbnaPfCcLM7CBOEKRtEE4QZmYHcYIAavJugzAzO5QTBEkVk0sQZmYHc4IgHQfhBGFmdhAnCNwGYWY2GicI0nEQA26DMDMr5ASBx0GYmY3GCYKkisltEGZmB3OCwL2YzMxG4wTBgdlch4cj61DMzCqGEwRJIzXgKb/NzAo4QZC0QQCuZjIzK+AEQVLFBHi6DTOzAk4QFCQILxpkZrafEwQH2iBcxWRmdoATBAfaIDwWwszsACcIknEQ4DYIM7NCThAUNlK7BGFmNsIJAicIM7PROEHgNggzs9E4QeBxEGZmo3GCoGAktcdBmJnt5wRBYS8mJwgzsxFOEEBNPp2sz1VMZmb7OUHgEoSZ2WicIDhQgnCCMDM7wAkCqMrnqMrJvZjMzAo4QaRqqnIeB2FmVsAJIlVb5XWpzcwKlSxBSLpJUoekFWMcb5V0u6RHJT0o6ayCYy2SfiBptaRVkl5cqjhH1FblPQ7CzKxAKUsQNwOXHeb4J4DlEbEIuAq4vuDY9cBPIuI04GxgVamCHFFbnXMbhJlZgZIliIi4F9hxmFPOAO5Oz10NLJQ0U9JU4KXAt9Nj/RGxq1RxjqjJ5+gfcgnCzGxElm0QjwBvAZB0AbAAmAscD3QCfy9pmaRvSZoy1ptIulbSEklLOjs7X3AwtdU5VzGZmRXIMkF8FmiRtBy4DlgGDAFVwHnANyLiXGAv8LGx3iQiboyIxRGxuL29/QUHU1uVdyO1mVmBqqw+OCK6gKsBJAl4ClgHNADPRsQD6ak/4DAJ4lhJejG5DcLMbERmJYi0p1JN+vJ9wL0R0RURW4BnJJ2aHnsl8Hip46n1OAgzs4OUrAQh6Vbg5UCbpGeBTwPVABFxA3A68B1JAawErin48euAW9IEso60pFFKNR4HYWZ2kJIliIi48nmO3w+cMsax5cDiUsQ1FrdBmJkdzCOpU7VVOfoG3AZhZjbCCSJVW+1xEGZmhZwgUjV5T7VhZlbICSKVTLXhBGFmNsIJIlVblVQxDQ9H1qGYmVUEJ4hUbVUewO0QZmapwyYIJeaVK5gs1VSly466HcLMDHieBBERAfxbmWLJ1JSapASxb2Aw40jMzCpDMVVMSyWdX/JIMtZUVw1AV48ThJkZFDeS+neBd0taTzKzqkgKF4tKGlmZNdUll6K7dyDjSMzMKkMxCeI1JY+iAhxIEC5BmJlBEVVMEbEeaAHemD5a0n0Tyv4qJpcgzMyAIhKEpA8BtwAz0sc/SLqu1IGVW7NLEGZmBymmiuka4HcjYi+ApM8B9wNfLWVg5dZc7xKEmVmhYnoxiWQp0BFD6b4JpbYqR3VeLkGYmaWKKUH8PfCApNvT128Cvl26kLIhiaa6avdiMjNLHTZBSMoBvwF+AVyS7r46IpaVOK5MNNVVuQRhZpY6bIKIiGFJX4+Ic4GlZYopM04QZmYHFNMGcZekt0qacO0Oh2qqdRWTmdmIYhLEHwHfB/okdUnqltRV4rgy0VRX5ak2zMxSxbRBXBYRvypTPJlqrncJwsxsxPPN5joMfK1MsWTObRBmZge4DaJAU101e/oHvaqcmRlH1gbRP9HbIJrrqoiAPf0uRZiZPe9AuYhoKkcglWBkRteungGa08n7zMwmq2Im65Ok90j6y/T1PEkXlD608huZ0dXtEGZmxVUx/S3wYuBd6es9wNdLFlGGmp0gzMz2K2pFuYg4T9IygIjYKammxHFlwqvKmZkdUEwJYkBSHggASe3AcEmjyohXlTMzO6CYBPEV4HZghqT/CfwS+F8ljSojXlXOzOyAYnox3SLpYeCVJOtAvCkiVpU8sgy4BGFmdkAxbRBExGpgdYljyVxddZ6afM4lCDMziqtiekEk3SSpQ9KKMY63Srpd0qOSHpR01iHH85KWSfrXUsU4muZ6T7dhZgYlTBDAzcBlhzn+CWB5RCwCrgKuP+T4h4CyV2W1NtSwc29/uT/WzKzilCxBRMS9wI7DnHIGcHd67mpgoaSZAJLmAq8HvlWq+MbS3lRLR3dfuT/WzKzijJkgRuZcGutxDD77EeAt6WddACwA5qbH/g/wZxTRnVbStZKWSFrS2dl51EG1N9XS6QRhZjZ2goiIpohoJqn6+Rgwh+QG/uckN/Cj9VmgRdJy4DpgGTAk6Q1AR0Q8XMybRMSNEbE4Iha3t7cfdVDtjUmCiPCMrmY2uRXTi+nyiDi74PU3JD0CfOpoPjgiuoCrIZnvCXgKWAf8PnC5pNcBdUCzpH+IiPcczecVq72plp6BIfb2D9FYW1QnLzOzCamYNoi9kt6d9irKSXo3sPdoP1hSS8GUHe8D7o2Iroj4eETMjYiFwDuBu8uVHCBJEICrmcxs0ismQbwLeAewNX28nQMT941J0q3A/cCpkp6VdI2k90t6f3rK6cAKSU8AryXptZQ5Jwgzs0QxI6mfBq440jeOiCuf5/j9wCnPc84vgF8c6WcfjRlNdYAThJlZMetBnCLprpEBb5IWSfqL0oeWjQMliN6MIzEzy1YxVUzfBD4ODABExKMkbQMTUkt9NVU50bnHJQgzm9yKSRANEfHgIfsm7FwUuZxoa/RYCDOzYhLENkkncmA9iLcBm0saVcY8WM7MrLhxEB8AbgROk7SRZLzCu0saVcbam2rZ2uU2CDOb3A6bINKV5P5rRLxK0hQgFxHd5QktO+2NtazYuDvrMMzMMnXYBBERQ5IuSbePenDceNHeVMv2vf0MDQf5nLIOx8wsE8VUMS2TdAfwfQpGUEfEbSWLKmMzmmsZGg527uunrbE263DMzDJRTIKoA7YDryjYF8DETRDpYLktu3udIMxs0ipmJPXV5Qikksyf1gDAhh37OGvO1IyjMTPLxvMmCEl1wDXAmSSlCQAi4g9LGFem5k2rB5IEYWY2WRUzDuJ7wCzgNcA9JGtCTOieTE111UybUsP67U4QZjZ5FZMgToqIvwT2RsR3SJYC/d3ShpW9+dMaeMYlCDObxIpJEAPp8y5JZwFTgRmlC6kyzJ/W4ComM5vUikkQN0pqBf4SuAN4HPh8SaOqAPOnNbBxVw8DQ8+7LLaZ2YRUTC+mb6Wb9wAnlDacyjF/WgNDw8HmXb3Mn96QdThmZmVXTC+mUdeejoi/OvbhVI6RpLBhxz4nCDOblIpak7rgMUSyPOjCEsZUEUbGQqzfMWlmGDEzO0gxVUxfLHwt6QvAT0sWUYWY2VxHTT7nhmozm7SKKUEcqoFkLMSEls+Jua31rN/mBGFmk1MxbRCPkS4WBOSBdmBCtz+MOGlGI092TOgxgWZmYypmsr43FGwPAlsjYsIuOVrotFlN/GzVVnoHhqirzmcdjplZWRVTxdRd8OgBmiVNG3mUNLqMnTqrmeGAtR17sg7FzKzsiilBLAXmATsBAS3AhvRYMIHHRpw2uwmAVZu7PKurmU06xZQg/gN4Y0S0RcR0kiqnOyPi+IiYsMkBYOH0KdRW5Xhii9shzGzyKSZBXBgR/zbyIiL+HbiodCFVjnxOnDyzkSe2OkGY2eRTTILYJOkvJC1MH58ENpU6sEpx6sxmVrsEYWaTUDEJ4kqSrq23p4/2dN+kcPrsJjq7+9i+py/rUMzMyqqYkdQ7gA8BSMoDUyKiq9SBVYrTZjUDsHJTFy89pT3jaMzMyud5SxCS/lFSs6QpwGPA45L+W+lDqwyL5k1FgmUbdmUdiplZWRVTxXRGWmJ4E/DvwPHAe0saVQVprqvm5BmNLN2wM+tQzMzKqpgEUS2pmiRB3BERAxyYemNSOG9+K8s27GR4eFL9b5vZJFdMgvg74GlgCnCvpAXA87ZBSLpJUoekFWMcb5V0u6RHJT2YLmeKpHmSfi7pcUkrJX2o+P+d0jhvfitdvYOs2+YR1WY2eTxvgoiIr0TEnIh4XUQEySjqS4t475uByw5z/BPA8ohYBFwFXJ/uHwT+NCLOAC4EPiDpjCI+r2TOW9ACwFK3Q5jZJHLE031H4nkn64uIe4EdhznlDODu9NzVwEJJMyNic0QsTfd3A6uAOUca57F0QlsjzXVVLHM7hJlNIi9kPYhj5RHgLQCSLgAWcMg6E5IWAucCD4z1JpKulbRE0pLOzs6SBJrLiRctaOWBpw6X78zMJpYsE8RngRZJy4HrgGUkS5oCIKkR+Bfgw4cbdxERN0bE4ohY3N5eunEKF5/UxrrOvWze3VOyzzAzqyTFzOaKpItI1qHef35EfPdoPji96V+dvr+Ap4B16etqkuRwS0TcdjSfc6xcfFIbAPet2cY7Fs/LOBozs9IrZqDc94AvAJcA56ePxUf7wZJaJNWkL98H3BsRXWmy+DawKiK+dLSfc6ycNquJtsZafrlmW9ahmJmVRTEliMUkg+WOaBCApFuBlwNtkp4FPg1UA0TEDcDpwHckBbASuCb90YtJBuI9llY/AXyicEbZLEjikpOmc9+abQwPB7mcsgzHzKzkikkQK4BZwOYjeeOIOOyEfhFxP3DKKPt/SbIwUcW55OR2frh8E6u2dHHmcV5AyMwmtmISRBvJ/EsPAvunNI2Iy0sWVYV66clJO8TdqzqcIMxswismQXym1EGMFzOa6zhvfgs/WbmF6155ctbhmJmVVDHTfd9TjkDGi9ecOYv//e+reWbHPuZNa8g6HDOzkimmF9OFkh6StEdSv6QhSZNmPYhDvebMWQDc+fjWjCMxMyutYgbKfY1kBbk1QD1Jl9SvlzKoSrawbQqnzmzipyu2ZB2KmVlJFTWSOiLWAvmIGIqIv+fwk/BNeK9fNJsHn97Bszv3ZR2KmVnJFJMg9qUD2pZL+rykPyny5yasN5+bzB34w2UbM47EzKx0irnRvzc974PAXmAe8NZSBlXp5k1r4ILjp3Hb0o0c4fhBM7Nxo5j1INaTDFybHRH/PSI+klY5TWpvPW8O67btZdkzXiPCzCamYnoxvRFYDvwkfX2OpDtKHVile93vzKahJs+tD2zIOhQzs5IoporpM8AFwC6AiFgOHF/CmMaFprpq3nTuHO54ZBO79vVnHY6Z2TFXTIIYiIjdh+xzxTvw3gsX0Dc4zPeXPJt1KGZmx1wxCWKlpHcBeUknS/oq8OsSxzUunD67mfMXtvK936xnaNg508wmlmISxHXAmSQT9d0KdAEfLmVQ48kfXnw8G3bs4yceOGdmE0wxvZj2RcQnI+L8dGnPT0ZEbzmCGw9efeYsTmibwjfuWesur2Y2oRTTi2mxpNskLZX06MijHMGNB/mc+KOXncCKjV3c59XmzGwCKaaK6RbgZpLBcW8seFjqTefOYfbUOr78syddijCzCaOYBNEZEXdExFMRsX7kUfLIxpHaqjzXveJklm3Yxd2rO7IOx8zsmCgmQXxa0rckXSnpLSOPkkc2zrx98VwWTG/gC3c+ybB7NJnZBFBMgrgaOIdkBteR6qU3lDKo8ag6n+Mjv3cKqzZ38S9LPS7CzMa/YpYcPT8iTi15JBPA5Wcfx82/fprP//QJXvs7s2msLebymplVpmJKEL+WdEbJI5kAJPGpN5xBZ3cfX71rTdbhmJkdlWISxIUka0E8kXZxfczdXMd27vxW3nn+PL553zoefdYzvZrZ+FVMHcikXj3uhfj4607n7tUd/NkPHuXH111CdX5Sr69kZuNUUetBjPYoR3Dj1dT6av7Hm85i9ZZu/u6e32YdjpnZC+KvtiXy6jNn8YZFs/nKXWtZs7U763DMzI6YE0QJfebyM5lSm+fD/7yc3oGhrMMxMzsiThAl1NZYyxfefjYrN3Xx1//6eNbhmJkdESeIEnvl6TP5o5edwC0PbOBHyzdmHY6ZWdGcIMrgo68+lfMXtvLx2x5jbceerMMxMyuKE0QZVOdzfPXK86ivznPtd5d4DWszGxecIMpk1tQ6bnjvi3h2Zw/Xfvdh+gbdaG1mla1kCULSTZI6JK0Y43irpNvT0dkPSjqr4Nhl6cjttZI+VqoYy+38hdP44jvO5sGnd/Dfvv+oZ301s4pWyhLEzRx+FPYngOURsQi4CrgeQFIe+DrwWuAM4MqJNBfUG88+jj+/7DTueGQTn/vpai8wZGYVq2TTjUbEvZIWHuaUM4DPpueulrRQ0kzgBGBtRKwDkPRPwBXAhOkn+v6XncDGXfv4u3vWUV+d58OvOiXrkMzMniPL+agfAd4C3CfpAmABMBeYAzxTcN6zwO+WP7zSkcRfXX4WfQPD/J+fraEqJz74ipOzDsvM7CBZJojPAtdLWg48BiwDjrjlVtK1wLUA8+fPP6YBllIuJz771kUMDQdfuPNJJPGBS0/KOiwzs/0ySxAR0UWyWh2SBDwFrAPqgXkFp84FxhxhFhE3AjcCLF68eFxV6Odz4m/efjbDEfzNT59g175+Pv7a08nllHVoZmbZJQhJLcC+iOgH3gfcGxFdkh4CTpZ0PElieCfwrqziLLV8TnzpHecwtb6ab973FNv39PO5ty3yFOFmlrmSJQhJtwIvB9okPQt8GqgGiIgbgNOB70gKYCVwTXpsUNIHgZ8CeeCmiFhZqjgrQS4nPnP5mUxvrOVL//Ek2/f289V3nUtzXXXWoZnZJKaJ1M1y8eLFsWTJkqzDOCq3PriBv/jhCo5vm8K3rlrMwrYpWYdkZhOYpIcjYvFox1yPUWGuvGA+37vmArbv6eOKr/+KX67ZlnVIZjZJOUFUoItObONHH7iEWc11XHXTA1z/szUMedS1mZWZE0SFmj+9gdv+60Vccc4cvvyzJ3nvtx+go7s367DMbBJxgqhgU2qr+NI7zubzb1vE0g07ed3193Hnyi1Zh2Vmk4QTRIWTxDsWz+OOD17CjKY6rv3ew3zk/y5nd89A1qGZ2QTnBDFOnDKziR9+4GL++BUn8aPlm3jNl+/lJys2e7I/MysZJ4hxpKYqx0defSq3/ZeLaGmo5v3/sJQ/vPkhNmzfl3VoZjYBOUGMQ2fPa+Ffr7uEv3j96Tz41A5+78v38NW71ngRIjM7ppwgxqmqfI73veQE7vrTl/Oq02fyxf94kt/70r3c8cgmL0RkZseEE8Q4N2tqHV9/93l875oLaKjJ88e3LuPyr//SA+zM7Kg5QUwQLzm5nX/745fw5d8/m517B3jPtx/gvd9+gIfX78w6NDMbpzwX0wTUNzjEP/xmA1+7ew079w1w0YnT+eArTuLFJ0wnmVndzCxxuLmYnCAmsL19g/zjAxu48b51dHb3cd78Fj5w6UlceuoMrzlhZoATxKTXOzDE95c8ww33rGPjrh6Ob5vCH7x4AW9bPI/G2iwXFTSzrDlBGAADQ8P822ObufnXT7Nswy4aa6t4++K5vOfCBZzY3ph1eGaWAScIe47lz+zi5l89xf97bDMDQ8H5C1t5x+J5vH7RbBpqXKowmyycIGxMHd293LZ0I//3oWdYt20vjbVVvPHs2VxxzhzOXziNvNsqzCY0Jwh7XhHBkvU7+eeHnuH/PbqZnoEhZjbX8vrfOY43nj2bc+a1uAeU2QTkBGFHZF//IHet6uDHj2ziF0900j80zNzWet6w6DhefeZMzpnb4l5QZhOEE4S9YF29A9y5cis/fmQTv1y7jaHhoK2xhktPncErT5/JS05uY4p7QpllYng46OjuY8fefs44rvkFvYcThB0Tu/b1c8+TnfxsVQe/eKKD7t5BavI5LjxxOi89uY2LT2rjtFlNrooyO0YGhobZsruXZ3f2sHFXDxt39vDszn3J9q4eNu/qpX9omPamWh765Kte0Gc4QdgxNzA0zENP7+DuVR3cvbqDddv2AtDWWMOLT2zj4hOnc/FJbcyb1pBxpGaVq3dgqODG38PGXfvYWJAMtnT1cujcmzOaapnTWs+clnrmtNYzr7WB+dMaeOkp7S8oBicIK7mNu3r41dpt/HrtNn712+10dvcBcNzUOl60cBqLF7TyogWtnDariaq8pwCziW9oONi2p4/Nu3vZvKsned594Oa/cVcP2/b0H/Qz+ZyY1VzHnNZ65rbWMzdNAnNaGpjbWs/sljpqq/LHNE4nCCuriGBtxx5+tXYbD63fycNP72RLVy8ADTV5zpnXwrnzW/idOVM587ipzG2td7WUjSuDQ8N0pjf/Lbt72bSrhy27e9nclbzevKuHrd19DB3y9b+mKsecluTmP6flQClgbmsDc1rrmdlUW/YvUE4QlqmIYNPuXpY8vYOH1+9kydM7eWJr9/5/PFPrqzlrTjNnzZnKWcdN5aw5U1kwrcE9pazsIoKunkE6unvp6O5Lnrv62NrVx5aunv0JoWOUm39ddY7ZU+uZPbWOWVPr0ud6ZjfXMbuljtlT62ltqK64L0NOEFZxegeGWL2lmxUbd7Ny025WbOziiS3d9A8NA8k/thPbGzl5RiMnz2za/zx/WoMH79kRGx4Oduzrp6Orb//Nv7O7j46uZHtr14F9fYPDz/n5+up8epOve04SGHk9tb7ybv7FOFyCcP9Ey0RddVLVdM68lv37+geHeXJrNys37ebJrXtY07GHB5/awQ+Xb9p/Tk1VjhPaprBgegMLpk9h/rSGZHvaFI5rqXP7xiTS0z/E9r19bN/TX/Dcz/Y9Bdt7+9jW3c+2PX0MjrLSYnNdFTOa65jRVMviBa37t9ubapnRVMeM5lpmNNXSWFs1Lm/+R8sJwipGTVUuqWaaM/Wg/d29A/y2cy9rtnaztmMPazv28NvOvfz8iU76C77t5XNiTks986bVM6v50KJ+5RbxLSlR7to3wK6efnbuHWB3T3/6eoBd+wbYsTfp67+tIBns6x99Dfa66hzTp9TS1ljDjKY6Tp/VnN7ok5v/yHZ7Uy111ce2wXeicYKwitdUV/2c0gYk1QZbu3tZv30fG7bvY/2OvazfnvQR//Vvt7F1lC6CNVU5Zk+tY2ZTHdMba5jeWMO0KbVMnzKyXUNbYy3TptTQ2lDj6qwi9Q8Os6dvkD29g3T1Duzf3tM3SHfvAF29g3SlN/tdIzf/gu3RqnVGVOfFtCk1TJ9Sy/TGGhZOb2B6Y7LdNiX5XU1vTH5v0xtrPNnkMeQraeNWLqe0/reeC0+Y/pzjg0PDbNvTz+bdaQ+T3b1s6Uqet+7u5cmt3exY18/OfQOjvr8EjTVVNNdX01RXlT6qaU6fm+qSYw01eeqq89Snj7rqPPU1uQP7avLUVSX7q/Min1NZSjERweBwMDgU9A8NMzg0zMBQMDA0zMDQMH2Dw/QMDNHbP0TPQProH6J3YIh9BfsOHB+mp3+IvX2DdPcN7E8AXb2DB5XkxlJTlaO1oZqW+hqmNlSzsK2BlvoWWhqqmZrub2mopqW+mpaGdLuhmvrqvEt9GXGCsAmrKp9jVlq9dDiDQ8Ps3DfAjr0Hqi+S7X66egbo7h35FjzA1q5e1nYk35K7ewef05OlWPmcqEof+ZyozucOes7nREQQwEg/kiCIOPAaOOicweGDE8DA0NF3QKmtylFfcyD51VbnaaqtYkZTHSe2V9FYW0VjXRVNtUnSLHzdWHdgX1NdlatzxiEnCJv0qvI52tOGSWgq+uci4sA37fSbd8/AEL0Dw/v39Q0mzyPfxoeG0m/1w8P7v90PjbxOjyWvA5GUYpLn5Bu00v8IMfKleuS8qnyOmnyOqpyorspRnSacqnyO6ryoqcpRlUu2q/M56qoPLuUcKP0c2HYV2+TmBGH2AkliSm2VJyu0CaukfQIl3SSpQ9KKMY5PlfRjSY9IWinp6oJjn0/3rZL0FbkS0sysrErdafxm4LLDHP8A8HhEnMRndzEAAAemSURBVA28HPiipBpJFwEXA4uAs4DzgZeVNlQzMytU0gQREfcCOw53CtCUlg4a03MH0/11QA1QC1QDW0sZq5mZHSzrYadfA04HNgGPAR+KiOGIuB/4ObA5ffw0IlaN9gaSrpW0RNKSzs7OcsVtZjbhZZ0gXgMsB44DzgG+JqlZ0kkkiWMuMAd4haSXjPYGEXFjRCyOiMXt7S9sPnQzM3uurBPE1cBtkVgLPAWcBrwZ+E1E7ImIPcC/Ay/OME4zs0kn6wSxAXglgKSZwKnAunT/yyRVSaomaaAetYrJzMxKo6QduCXdStI7qU3Ss8CnSRqciYgbgL8Gbpb0GMl4nz+PiG2SfgC8gqRdIoCfRMSPSxmrmZkdbEKtByGpE1h/hD/WBmwrQTjHQqXGVqlxQeXG5riOXKXGVqlxwQuLbUFEjNqAO6ESxAshaclYi2VkrVJjq9S4oHJjc1xHrlJjq9S44NjHlnUbhJmZVSgnCDMzG5UTBNyYdQCHUamxVWpcULmxOa4jV6mxVWpccIxjm/RtEGZmNjqXIMzMbFROEGZmNqpJnSAkXSbpCUlrJX0swzjmSfq5pMfTNTA+lO7/jKSNkpanj9dlFN/Tkh5LY1iS7psm6T8krUmfW8sc06kF12W5pC5JH87qmo229slY10iJr6R/d49KOq/Mcf2NpNXpZ98uqSXdv1BST8G1u6HMcY35u5P08fR6PSHpNaWK6zCx/XNBXE9LWp7uL+c1G+s+Ubq/s4iYlA8gD/wWOIFkWvFHgDMyimU2cF663QQ8CZwBfAb4aAVcq6eBtkP2fR74WLr9MeBzGf8utwALsrpmwEuB84AVz3eNgNeRzC8m4ELggTLH9WqgKt3+XEFcCwvPy+B6jfq7S/8tPEIy9f/x6b/bfDljO+T4F4FPZXDNxrpPlOzvbDKXIC4A1kbEuojoB/4JuCKLQCJic0QsTbe7SeadmpNFLEfgCuA76fZ3gDdlGMsrgd9GxJGOoj9mYvS1T8a6RlcA343Eb4AWSbPLFVdE3BkRg+nL35DMmlxWY1yvsVwB/FNE9EXEU8Bakn+/ZY9NkoB3ALeW6vPHcpj7RMn+ziZzgpgDPFPw+lkq4KYsaSFwLvBAuuuDafHwpnJX4xQI4E5JD0u6Nt03MyI2p9tbgJnZhAbAOzn4H2wlXDMY+xpV0t/eH5J8yxxxvKRlku7RGFPsl9hov7tKul4vAbZGxJqCfWW/ZofcJ0r2dzaZE0TFkdQI/Avw4YjoAr4BnEiyVsZmkqJtFi6JiPOA1wIfkPTSwoORlGcz6S8tqQa4HPh+uqtSrtlBsrxGY5H0SZIVHG9Jd20G5kfEucBHgH+U1FzGkCryd3eIKzn4y0jZr9ko94n9jvXf2WROEBuBeQWv56b7MqFkWvN/AW6JiNsAImJrRAxFxDDwTUpYrD6ciNiYPncAt6dxbB0prqbPHVnERpK0lkbE1jTGirhmqbGuUeZ/e5L+E/AG4N3pTYW0Cmd7uv0wSV3/KeWK6TC/u8yvF4CkKuAtwD+P7Cv3NRvtPkEJ/84mc4J4CDhZ0vHpt9B3AndkEUhar/ltYFVEfKlgf2F94ZuBFYf+bBlimyKpaWSbpIFzBcm1+oP0tD8AflTu2FIHfaOrhGtWYKxrdAdwVdrL5EJgd0EVQclJugz4M+DyiNhXsL9dUj7dPgE4mWR9lnLFNdbv7g7gnZJqJR2fxvVgueIq8CpgdUQ8O7KjnNdsrPsEpfw7K0fre6U+SFr5nyTJ+p/MMI5LSIqFj5Iswbo8je17JGtiPJr+smdnENsJJD1IHgFWjlwnYDpwF7AG+BkwLYPYpgDbgakF+zK5ZiRJajMwQFLXe81Y14ikV8nX07+7x4DFZY5rLUnd9Mjf2g3puW9Nf8fLgaXAG8sc15i/O+CT6fV6AnhtuX+X6f6bgfcfcm45r9lY94mS/Z15qg0zMxvVZK5iMjOzw3CCMDOzUTlBmJnZqJwgzMxsVE4QZmY2KicIs8OQtOcYvc9nJH20iPNulvS2Y/GZZkfLCcLMzEblBGFWBEmNku6StFTJ2hhXpPsXKllb4WZJT0q6RdKrJP0qnZ+/cKqPsyXdn+7/z+nPS9LXlKxz8DNgRsFnfkrSQ5JWSLoxHUlrVjZOEGbF6QXeHMmkhZcCXyy4YZ9EMrHcaenjXSSjXj8KfKLgPRYBrwBeDHxK0nEkU0qcSjKv/1XARQXnfy0izo+Is4B6krmTzMqmKusAzMYJAf8rncl2mGTa5JFplZ+KiMcAJK0E7oqIkPQYyYIyI34UET1Aj6Sfk0xG91Lg1ogYAjZJurvg/Esl/RnQAEwjmdLhxyX7PzQ7hBOEWXHeDbQDL4qIAUlPA3Xpsb6C84YLXg9z8L+xQ+e1GXOeG0l1wN+SzJ/zjKTPFHyeWVm4ismsOFOBjjQ5XEqyvOmRukJSnaTpwMtJZhS+F/h9Sfl0NtNL03NHksG2dP5/92yysnMJwqw4twA/TquNlgCrX8B7PAr8HGgD/joiNkm6naRd4nFgA3A/QETskvRNkimvt5AkE7Oy8myuZmY2KlcxmZnZqJwgzMxsVE4QZmY2KicIMzMblROEmZmNygnCzMxG5QRhZmaj+v9dWcQ/gD0fLAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90RfKv8JQdBY"
      },
      "source": [
        "regardless of used model for prediction, the next two cells provide prediction in desired format of kaggle website"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9qs5-wTOrVwg"
      },
      "source": [
        "import csv\r\n",
        "with open('prediction.csv', 'w', newline='') as file:\r\n",
        "    writer = csv.writer(file)\r\n",
        "    writer.writerow(['Id', 'SalePrice'])\r\n",
        "    for i in range(len(test_dataset)):\r\n",
        "      writer.writerow([test_dataset[i][0].astype(int),prediction[i]])"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "ug206l0Oo3qH",
        "outputId": "956a57c3-abcd-43cc-bb75-e4059312dc33"
      },
      "source": [
        "from google.colab import files\r\n",
        "files.download(\"prediction.csv\")"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_b684990b-aa5f-49d8-8a11-440fb36f4905\", \"prediction.csv\", 22457)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}